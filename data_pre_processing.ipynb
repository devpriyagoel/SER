{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_pre_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devpriyagoel/Speech-Emotion-Recognition/blob/master/data_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJtG4Znwuqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrWv_825QEml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "2abfefd1-2a18-4217-ee0d-1afa290292aa"
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=00536b0a3b23a1a3c43e4527c42d3fafb584a31c61b83defd14e1d313956b35e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnjW03Sqk4_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import python_speech_features as ps"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uELGvmKajZfz",
        "colab_type": "text"
      },
      "source": [
        "Read data from IEMOCAP database and prepare train, test, validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbSJ47OJgtmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreProcess:\n",
        " \n",
        "    def __init__(self, root_dir):\n",
        "        self.eps = 1e-5\n",
        "        self.filter_num = 40\n",
        "        self.frame_num = 300\n",
        "        self.num_per_emo = 300\n",
        "        self.root_dir = root_dir\n",
        " \n",
        "        self.train_num = 2928\n",
        "        self.test_utterance_num = 259  # the number of test utterance\n",
        "        self.valid_utterance_num = 298\n",
        "        self.test_segment_num = 420  # the number of test 2s segments\n",
        "        self.valid_segment_num = 436\n",
        " \n",
        "        self.train_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.test_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        self.valid_emt = {'hap': 0, 'ang': 0, 'neu': 0, 'sad': 0}\n",
        "        \n",
        "        self.train_data = np.empty((self.train_num, self.frame_num, self.filter_num, 3), dtype=np.float32)\n",
        "        self.test_data = np.empty((self.test_segment_num, self.frame_num, self.filter_num, 3), dtype=np.float32)\n",
        "        self.valid_data = np.empty((self.valid_segment_num, self.frame_num, self.filter_num, 3), dtype=np.float32)\n",
        "        \n",
        "        self.train_label = np.empty((self.train_num, 1), dtype=np.int8)\n",
        "        self.test_label_utterance = np.empty((self.test_utterance_num, 1), dtype=np.int8)\n",
        "        self.valid_label_utterance = np.empty((self.valid_utterance_num, 1), dtype=np.int8)\n",
        "        self.test_label_segment = np.empty((self.test_segment_num, 1), dtype=np.int8)\n",
        "        self.valid_label_segment = np.empty((self.valid_segment_num, 1), dtype=np.int8)\n",
        "        \n",
        "        self.test_segments_per_utterance = np.arange(self.test_utterance_num)\n",
        "        self.valid_segments_per_utterance = np.arange(self.valid_utterance_num)\n",
        "        \n",
        "        self.train_num = 0\n",
        "        self.test_segment_num = 0\n",
        "        self.valid_segment_num = 0\n",
        "        self.test_utterance_num = 0\n",
        "        self.valid_utterance_num = 0\n",
        "        self.wav_files = None\n",
        "        self.mean1, self.mean2, self.mean3 = 0, 0, 0\n",
        "        self.std1, self.std2, self.std3 = 0, 0, 0\n",
        " \n",
        "    def read_wav_file(self, wav_filename):\n",
        "        \"\"\"Read the audio files in wav format and store the wave data\"\"\"\n",
        "        wav_file = wave.open(wav_filename, 'r')\n",
        "        params = wav_file.getparams()\n",
        "        _, _, framerate, wav_length = params[:4]\n",
        "        str_data = wav_file.readframes(wav_length)\n",
        "        wave_data = np.frombuffer(str_data, dtype=np.short)\n",
        "        wav_file.close()\n",
        "        mel_spec = ps.logfbank(wave_data, framerate, nfilt=self.filter_num)\n",
        "        delta1 = ps.delta(mel_spec, 2)\n",
        "        delta2 = ps.delta(delta1, 2)\n",
        "        return mel_spec, delta1, delta2\n",
        " \n",
        "    @staticmethod\n",
        "    def generate_label(emotion):\n",
        "        if emotion == 'ang':\n",
        "            return 0\n",
        "        elif emotion == 'sad':\n",
        "            return 1\n",
        "        elif emotion == 'hap':\n",
        "            return 2\n",
        "        elif emotion == 'neu':\n",
        "            return 3\n",
        "        elif emotion == 'fear':\n",
        "            return 4\n",
        "        return 5\n",
        " \n",
        "    @staticmethod\n",
        "    def parse_emo_file(emo_file_name):\n",
        "        emo_map = {}\n",
        "        with open(emo_file_name, 'r') as emo_file:\n",
        "            while True:\n",
        "                line = emo_file.readline()\n",
        "                if not line:\n",
        "                    break\n",
        "                if line[0] != '[':\n",
        "                    continue\n",
        "                t = line.split()\n",
        "                emo_map[t[3]] = t[4]\n",
        "        return emo_map\n",
        " \n",
        "    def read_IEMOCAP(self):\n",
        "        \"\"\"Read the data files and generate a dict with generated features\"\"\"\n",
        "        wav_file_features = {}\n",
        "        for session in sorted(os.listdir(self.root_dir)):\n",
        "            if session[0] != 'S':\n",
        "                continue\n",
        "            wav_dir = os.path.join(self.root_dir, session, 'sentences', 'wav')\n",
        "            emo_labels_dir = os.path.join(self.root_dir, session, 'dialog', 'EmoEvaluation')\n",
        "            for impro in sorted(os.listdir(wav_dir)):\n",
        "                if impro[7] != 'i':\n",
        "                    continue\n",
        "                emo_file_name = os.path.join(emo_labels_dir, impro + '.txt')\n",
        "                emo_map = self.parse_emo_file(emo_file_name)\n",
        "                file_dir = os.path.join(wav_dir, impro, '*.wav')\n",
        "                files = glob.glob(file_dir)\n",
        "                for filename in sorted(files):\n",
        "                    wav_name = os.path.basename(filename)\n",
        "                    wav_name = os.path.splitext(wav_name)[0]\n",
        "                    emotion = emo_map[wav_name]\n",
        "                    if emotion not in ['hap', 'ang', 'neu', 'sad']:\n",
        "                        continue\n",
        "                    mel_spec, delta1, delta2 = self.read_wav_file(filename)\n",
        "                    wav_file_features[wav_name] = {\n",
        "                        'emotion': emotion,\n",
        "                        'mel_spec': mel_spec,\n",
        "                        'delta1': delta1,\n",
        "                        'delta2': delta2\n",
        "                    }\n",
        "        self.wav_files = wav_file_features\n",
        "        # print(self.wav_files)\n",
        " \n",
        "    def add_to_set(self, part, delta11, delta21, emotion, set_type):\n",
        "        # TODO extend it for test validation\n",
        "        if set_type == 'train':\n",
        "            self.train_data[self.train_num, :, :, 0] = part\n",
        "            self.train_data[self.train_num, :, :, 1] = delta11\n",
        "            self.train_data[self.train_num, :, :, 2] = delta21\n",
        "            self.train_label[self.train_num] = self.generate_label(emotion)\n",
        "            self.train_emt[emotion] += 1\n",
        "            self.train_num += 1\n",
        "        elif set_type == 'test':\n",
        "            self.test_data[self.test_segment_num, :, :, 0] = part\n",
        "            self.test_data[self.test_segment_num, :, :, 1] = delta11\n",
        "            self.test_data[self.test_segment_num, :, :, 2] = delta21\n",
        "            self.test_label_segment[self.test_segment_num] = self.generate_label(emotion)\n",
        "            self.test_emt[emotion] += 1\n",
        "            self.test_segment_num += 1\n",
        "        else:\n",
        "            self.valid_data[self.valid_segment_num, :, :, 0] = part\n",
        "            self.valid_data[self.valid_segment_num, :, :, 1] = delta11\n",
        "            self.valid_data[self.valid_segment_num, :, :, 2] = delta21\n",
        "            self.valid_label_segment[self.valid_segment_num] = self.generate_label(emotion)\n",
        "            self.valid_emt[emotion] += 1\n",
        "            self.valid_segment_num += 1\n",
        "        # print('\\t'.join((str(train_num), wavname, '0', 'self.frame_num', emotion)))\n",
        " \n",
        "    @staticmethod\n",
        "    def find_set(wav_name):\n",
        "        \"\"\"returns whether the wav_name should be part of train/test/validation set\"\"\"\n",
        "        if wav_name[4] in ['1', '2', '3', '4']:\n",
        "            return 'train'\n",
        "        if wav_name[-4] == 'M':\n",
        "            return 'test'\n",
        "        return 'validation'\n",
        " \n",
        "    def data_padding(self, data):\n",
        "        \"\"\"Padding short segments of data with 0s\"\"\"\n",
        "        return np.pad(data, ((0, self.frame_num - data.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
        " \n",
        "    def generate_data(self):\n",
        "        \"\"\"generates train test validation sets before calculating zscore \"\"\"\n",
        "        for wav_name in sorted(self.wav_files.keys()):\n",
        "            part = self.wav_files[wav_name]['mel_spec']\n",
        "            delta11 = self.wav_files[wav_name]['delta1']\n",
        "            delta21 = self.wav_files[wav_name]['delta2']\n",
        "            emotion = self.wav_files[wav_name]['emotion']\n",
        "            time = part.shape[0]\n",
        "            set_type = self.find_set(wav_name)  # train/test/validation\n",
        " \n",
        "            if time <= self.frame_num:\n",
        "                part = self.data_padding(part)\n",
        "                delta11 = self.data_padding(delta11)\n",
        "                delta21 = self.data_padding(delta21)\n",
        "                start_times = [0]\n",
        "            elif emotion == 'hap' and set_type == 'train':\n",
        "                frames = divmod(time - self.frame_num, 100)[0] + 1\n",
        "                start_times = [i * 100 for i in range(frames)]\n",
        "            else:\n",
        "                start_times = [0, time - self.frame_num]\n",
        " \n",
        "            end_times = [i + self.frame_num for i in start_times]\n",
        " \n",
        "            for begin, end in zip(start_times, end_times):\n",
        "                self.add_to_set(part[begin:end, :], delta11[begin:end, :], delta21[begin:end, :], emotion, set_type)\n",
        "            \n",
        "            if set_type == 'test':\n",
        "                self.test_label_utterance[self.test_utterance_num] = self.generate_label(emotion)\n",
        "                self.test_segments_per_utterance[self.test_utterance_num] = len(start_times)\n",
        "                self.test_utterance_num = self.test_utterance_num + 1\n",
        " \n",
        "            if set_type == 'validation':\n",
        "                self.valid_label_utterance[self.valid_utterance_num] = self.generate_label(emotion)\n",
        "                self.valid_segments_per_utterance[self.valid_utterance_num] = len(start_times)\n",
        "                self.valid_utterance_num = self.valid_utterance_num + 1\n",
        " \n",
        "    def calculate_zscore(self):\n",
        "        \"\"\"calculates zscore from train data \"\"\"\n",
        "        self.mean1 = np.mean(self.train_data[:, :, :, 0].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "        self.mean2 = np.mean(self.train_data[:, :, :, 1].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "        self.mean3 = np.mean(self.train_data[:, :, :, 2].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "        self.std1 = np.std(self.train_data[:, :, :, 0].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "        self.std2 = np.std(self.train_data[:, :, :, 1].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "        self.std3 = np.std(self.train_data[:, :, :, 2].reshape(self.train_num * self.frame_num, self.filter_num), axis=0)\n",
        "    \n",
        "    def standardize_data(self):\n",
        "        \"\"\"Standardize train test validation sets after the calculation of zscore\"\"\"\n",
        "        for i in range(self.train_num):\n",
        "            self.train_data[i, :, :, 0] = (self.train_data[i, :, :, 0] - self.mean1) / (self.std1 + self.eps)\n",
        "            self.train_data[i, :, :, 1] = (self.train_data[i, :, :, 1] - self.mean2) / (self.std2 + self.eps)\n",
        "            self.train_data[i, :, :, 2] = (self.train_data[i, :, :, 2] - self.mean3) / (self.std3 + self.eps)\n",
        " \n",
        "        for i in range(self.test_segment_num):\n",
        "            self.test_data[i, :, :, 0] = (self.test_data[i, :, :, 0] - self.mean1) / (self.std1 + self.eps)\n",
        "            self.test_data[i, :, :, 1] = (self.test_data[i, :, :, 1] - self.mean2) / (self.std2 + self.eps)\n",
        "            self.test_data[i, :, :, 2] = (self.test_data[i, :, :, 2] - self.mean3) / (self.std3 + self.eps)\n",
        " \n",
        "        for i in range(self.valid_segment_num):\n",
        "            self.valid_data[i, :, :, 0] = (self.valid_data[i, :, :, 0] - self.mean1) / (self.std1 + self.eps)\n",
        "            self.valid_data[i, :, :, 1] = (self.valid_data[i, :, :, 1] - self.mean2) / (self.std2 + self.eps)\n",
        "            self.valid_data[i, :, :, 2] = (self.valid_data[i, :, :, 2] - self.mean3) / (self.std3 + self.eps)\n",
        " \n",
        "    def class_indices(self):\n",
        "        \"\"\"\"Index of each emotion class instance in the training data\"\"\"\n",
        "        hap_index = np.arange(self.train_emt['hap'])\n",
        "        neu_index = np.arange(self.train_emt['neu'])\n",
        "        sad_index = np.arange(self.train_emt['sad'])\n",
        "        ang_index = np.arange(self.train_emt['ang'])\n",
        "        h2 = 0\n",
        "        a0 = 0\n",
        "        n3 = 0\n",
        "        s1 = 0\n",
        "        for i in range(self.train_num):\n",
        "            if self.train_label[i] == 0:\n",
        "                ang_index[a0] = i\n",
        "                a0 = a0 + 1\n",
        "            elif self.train_label[i] == 1:\n",
        "                sad_index[s1] = i\n",
        "                s1 = s1 + 1\n",
        "            elif self.train_label[i] == 2:\n",
        "                hap_index[h2] = i\n",
        "                h2 = h2 + 1\n",
        "            else:\n",
        "                neu_index[n3] = i\n",
        "                n3 = n3 + 1\n",
        " \n",
        "        return hap_index, sad_index, neu_index, ang_index\n",
        " \n",
        "    def generate_training_batch(self, hap_index, sad_index, neu_index, ang_index):\n",
        "        \"\"\"Generating a training batch with self.frame_num segments from each emotion\"\"\"\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(neu_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(hap_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(sad_index)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(ang_index)\n",
        " \n",
        "        train_label = np.empty((4 * self.num_per_emo, 1), dtype=np.int8)\n",
        "        train_data = np.empty((4 * self.num_per_emo, self.frame_num, self.filter_num, 3), dtype=np.float32)\n",
        "        train_data[0:self.num_per_emo] = self.train_data[hap_index[0:self.num_per_emo]].copy()\n",
        "        train_label[0:self.num_per_emo] = self.train_label[hap_index[0:self.num_per_emo]].copy()\n",
        "        train_data[self.num_per_emo:2 * self.num_per_emo] = self.train_data[sad_index[0:self.num_per_emo]].copy()\n",
        "        train_label[self.num_per_emo:2 * self.num_per_emo] = self.train_label[sad_index[0:self.num_per_emo]].copy()\n",
        "        train_data[2 * self.num_per_emo:3 * self.num_per_emo] = self.train_data[neu_index[0:self.num_per_emo]].copy()\n",
        "        train_label[2 * self.num_per_emo:3 * self.num_per_emo] = self.train_label[neu_index[0:self.num_per_emo]].copy()\n",
        "        train_data[3 * self.num_per_emo:4 * self.num_per_emo] = self.train_data[ang_index[0:self.num_per_emo]].copy()\n",
        "        train_label[3 * self.num_per_emo:4 * self.num_per_emo] = self.train_label[ang_index[0:self.num_per_emo]].copy()\n",
        " \n",
        "        arr = np.arange(4 * self.num_per_emo)\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(arr)\n",
        "        train_data = train_data[arr[0:]]\n",
        "        train_label = train_label[arr[0:]]\n",
        " \n",
        "        output = './processed_data.pkl'\n",
        "        f = open(output, 'wb')\n",
        "        pickle.dump((\n",
        "            train_data, train_label,\n",
        "            self.test_data, self.test_label_utterance, self.test_label_segment, self.test_segments_per_utterance,\n",
        "            self.valid_data, self.valid_label_utterance, self.valid_label_segment, self.valid_segments_per_utterance),\n",
        "            f)\n",
        "        f.close()\n",
        " \n",
        "    def preprocess(self):\n",
        "        \"\"\"Process the audio files to generate train/test/validation data with extracted features\"\"\"\n",
        "        self.read_IEMOCAP()\n",
        "        self.generate_data()\n",
        "        self.calculate_zscore()\n",
        "        self.standardize_data()\n",
        " \n",
        "        hap_index, sad_index, neu_index, ang_index = self.class_indices()\n",
        "        self.generate_training_batch(hap_index, sad_index, neu_index, ang_index)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4gR2zl1V0Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgY-4n3KF3y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "da7682ff-5ced-4465-a611-011e418dacdd"
      },
      "source": [
        "import sys\n",
        "# check the path\n",
        "path_to_code_files = '/content/drive/My Drive/BTP - Dev Priya and Kushagra/Speech Emotion Recognition/Code'\n",
        "sys.path.append(path_to_code_files)\n",
        "%cd \"/content/drive/My Drive/BTP - Dev Priya and Kushagra/Speech Emotion Recognition/Code\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/BTP - Dev Priya and Kushagra/Speech Emotion Recognition/Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka-VCIXVqtsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_iemocap = '/content/drive/My Drive/BTP - Dev Priya and Kushagra/Licensed_Data/IEMOCAP'\n",
        "p = PreProcess(path_to_iemocap)\n",
        "p.preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}